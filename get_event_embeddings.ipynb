{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import time\n",
    "\n",
    "import gensim\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import bokeh.plotting as bp\n",
    "from bokeh.models import HoverTool, BoxSelectTool\n",
    "from bokeh.plotting import figure, show, output_notebook\n",
    "from bokeh.models import ColumnDataSource, ColorBar\n",
    "from bokeh.palettes import Category20\n",
    "from bokeh.models import CategoricalColorMapper\n",
    "from bokeh.plotting import ColumnDataSource\n",
    "\n",
    "import alignment_data    as ad\n",
    "import feature_extractor as fe\n",
    "import player_sequential as ps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelize the problem as a NLP problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to compute embeddings of the numerous distinct kinds of events that appear in the Opta dataset.\n",
    "More specifically, there are roughly ~40 different types of events, for instance Pass, Goal, Foul, Card, Out, ... each of them being also specified by different qualifiers. That is, a Shot was it a Volley ? a Lob ? a Deflection ? Followed a Dribble ? A Pass was it a Long Ball ? a Cross ? a Corner ?\n",
    "<br>\n",
    "\n",
    "Each of these events is also specified by the pitch zone in which it took place (Left zone ? Right Zone ? Back zone ? etc...) and which body part was involved (Left foot ? Right foot ? Head ? etc...).\n",
    "\n",
    "Finally, each event is also associated to some outcome : for instance, a Pass was it successfull ? \n",
    "\n",
    "<br>\n",
    "Based on this, we denote each event by a tuple (event type, outcome, qualifiers, body part, pitch zone), and use the MD5 hashing library to map it to a unique \"word\". We then modelize a game as a kind of NLP problem : \n",
    "\n",
    "There are two agents speaking (the two teams), each of them will speak with some words (the events) to form some sentences (a sequence of actions without losing the ball). Eventually, the agents will consistently try to interrupt themselves (by recovering the ball) to form a new sentence.\n",
    "\n",
    "<br>\n",
    "The goal of this notebook is to learn usefull event embeddings that will serve later to train the models to our specific task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get event embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We achieve this with the Word2vec framework, in its Skip-Gram fashion. Essentially we train a Dense model to predict weither two events are likely to appear together in a same window of W = 5 events.\n",
    "\n",
    "We generate pairs :\n",
    "\n",
    "(event1, event2, 1) for two events that co-appears in a 5-window\n",
    "<br>\n",
    "(event1, event2, 0) for two events that do not co-appears in a 5-window\n",
    "\n",
    "And then train a supervised model as :\n",
    "\n",
    "<img src="imgs/network_emb.png" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read the dataset, parse the different kind of events and compute a unique MD5-HASH that will be used as a word to identify a (event type, outcome, qualifiers, body part, pitch zone) event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done in 00m48s\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../../French Ligue One 20162017 season - Match Day 1- 19/parsed_matches.csv', low_memory=False)\n",
    "\n",
    "t0 = time.time()\n",
    "df = ad.align_events(df)\n",
    "res = fe.extract_features(df)\n",
    "id2cols = dict(enumerate(res.columns))\n",
    "hashes = res.apply(np.nonzero, axis=1).apply(sum)\n",
    "hashes = hashes.apply(lambda x: \" \".join(sorted([id2cols[k] for k in x])))\n",
    "df['desc'] = hashes\n",
    "df['hash'] = hashes.apply(ps.get_hash).tolist()\n",
    "\n",
    "print(\"Done in {:02d}m{:02d}s\".format(*divmod(int(time.time() - t0), 60)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, SPLIT is a variable that indicates weither the possession of ball changed, or if there was an interruption (Goal event, ball out of spitch, formation change, ...). That can be seen as a indicator that one of two agents (ie. teams) stopped speaking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17689 docs\n",
      "Average length of doc : 18\n"
     ]
    }
   ],
   "source": [
    "hash2text = {k: v for _, (k, v) in df[['hash', 'desc']].drop_duplicates().iterrows()}\n",
    "hash2event = {k: v for _, (k, v) in df[['hash', 'type_id']].drop_duplicates().iterrows()}\n",
    "\n",
    "docs = df.groupby(['match_id', 'period_id', \"SPLIT\"]).agg({\"hash\": lambda x : \" \".join(x)}).hash.tolist()\n",
    "docs = [d for d in docs if len(d.split())>1]\n",
    "\n",
    "print(\"%d docs\" % len(docs))\n",
    "print(\"Average length of doc : %d\" % np.mean([len(d.split()) for d in docs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words :  1182\n"
     ]
    }
   ],
   "source": [
    "ev2vec = Word2Vec(size=200, window=5, min_count=0, sg=1, iter=15)\n",
    "ev2vec.build_vocab([d.split() for d in docs])\n",
    "ev2vec.train([d.split() for d in docs], total_examples=ev2vec.corpus_count, epochs=ev2vec.epochs)\n",
    "print('Number of words : ', len(ev2vec.wv.vocab)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the event embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute a TSNE reduction of the embeddings to be able to visualize them in a 2D-plan (tSNE will find vectors in a lower dimensional space and try to minimize the KL divergence between their distribution and the original 200-dims vectors distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 10 nearest neighbors...\n",
      "[t-SNE] Indexed 1182 samples in 0.022s...\n",
      "[t-SNE] Computed neighbors for 1182 samples in 0.396s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 1182\n",
      "[t-SNE] Computed conditional probabilities for sample 1182 / 1182\n",
      "[t-SNE] Mean sigma: 0.092489\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 88.986221\n",
      "[t-SNE] Error after 10000 iterations: 1.167459\n"
     ]
    }
   ],
   "source": [
    "event_vectors = [ev2vec.wv[w] for w in ev2vec.wv.vocab.keys()]\n",
    "\n",
    "tsne_model = TSNE(n_components=2, random_state=0, n_iter=10000, perplexity=3, verbose=True)\n",
    "tsne_ev2v = tsne_model.fit_transform(event_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>text</th>\n",
       "      <th>event_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-77.487419</td>\n",
       "      <td>86.249336</td>\n",
       "      <td>attempt_saved shot shot_box_left shot_right_fo...</td>\n",
       "      <td>Attempt Saved</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65.147125</td>\n",
       "      <td>46.680622</td>\n",
       "      <td>pass pass_cross pass_direct pass_fail pass_fre...</td>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29.067633</td>\n",
       "      <td>-124.074257</td>\n",
       "      <td>goal goal_box_centre goal_individual_play goal...</td>\n",
       "      <td>Goal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25.560226</td>\n",
       "      <td>-50.177837</td>\n",
       "      <td>pass pass_2nd_assist pass_chipped pass_cross p...</td>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67.164398</td>\n",
       "      <td>-1.298402</td>\n",
       "      <td>commit_foul foul_center foul_elbow/violent_con...</td>\n",
       "      <td>Foul</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           x           y                                               text  \\\n",
       "0 -77.487419   86.249336  attempt_saved shot shot_box_left shot_right_fo...   \n",
       "1  65.147125   46.680622  pass pass_cross pass_direct pass_fail pass_fre...   \n",
       "2  29.067633 -124.074257  goal goal_box_centre goal_individual_play goal...   \n",
       "3  25.560226  -50.177837  pass pass_2nd_assist pass_chipped pass_cross p...   \n",
       "4  67.164398   -1.298402  commit_foul foul_center foul_elbow/violent_con...   \n",
       "\n",
       "      event_type  \n",
       "0  Attempt Saved  \n",
       "1           Pass  \n",
       "2           Goal  \n",
       "3           Pass  \n",
       "4           Foul  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsne_df = pd.DataFrame(tsne_ev2v, columns=['x', 'y'])\n",
    "tsne_df['text'] = [hash2text[e] for e in ev2vec.wv.vocab.keys()]\n",
    "tsne_df['event_type'] = [hash2event[e] for e in ev2vec.wv.vocab.keys()]\n",
    "\n",
    "tsne_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the 20 most frequent type of events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filter_ = tsne_df.event_type.value_counts().index[:20]\n",
    "tsne_df = tsne_df[tsne_df.event_type.isin(filter_)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_notebook()\n",
    "source = ColumnDataSource(tsne_df)\n",
    "color_map = CategoricalColorMapper(factors = tsne_df.event_type.unique(),\n",
    "                                   palette = Category20[len(tsne_df.event_type.unique()[:20])])\n",
    "\n",
    "plot_vecs = bp.figure(plot_width=800, plot_height=800, title=\"A map of %d word vectors\" % len(ev2vec.wv.vocab),\n",
    "    tools=\"pan,wheel_zoom,box_zoom,reset,hover,previewsave\",\n",
    "    x_axis_type=None, y_axis_type=None, min_border=1)\n",
    "\n",
    "#plot_vecs.background_fill_color = \"beige\"\n",
    "#plot_vecs.background_fill_alpha = .5\n",
    "\n",
    "plot_vecs.scatter(x='x', y='y', size = 15, source=tsne_df,\n",
    "                  color={\"field\": \"event_type\", \"transform\": color_map},\n",
    "                  line_color = \"black\",\n",
    "                  legend = \"event_type\",\n",
    "                  fill_alpha=1, line_width=1)\n",
    "plot_vecs.legend.location = 'top_left'\n",
    "plot_vecs.legend.background_fill_alpha = 1\n",
    "plot_vecs.legend.border_line_width = 5\n",
    "plot_vecs.legend.border_line_color = \"black\"\n",
    "\n",
    "\n",
    "hover = plot_vecs.select(dict(type=HoverTool))\n",
    "hover.tooltips={\"event_type\": \"@event_type\"}\n",
    "show(plot_vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"./imgs/event_embeddings.png\" width=800 height=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different words (actions) that belong to the same type of event are nicely clustered together and one can observe that for instance, common events such as Pass and Shots are placed evenly all over the points, and Fouls and Cards are often placed in similar places, same with Tackle/Challenge/Dispossessed, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't forget to save the learned embeddings :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ev2vec.wv.save_word2vec_format(fname=\"./embeddings/_event_vectors_200dim_15epochs.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
